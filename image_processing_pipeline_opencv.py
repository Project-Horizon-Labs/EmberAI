# -*- coding: utf-8 -*-
"""Image Processing Pipeline OpenCV.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Pa96WAeNQODwKh0ttX7uSVQOoSNSYhYH
"""

from google.colab import drive

# Unmount the drive if it's already mounted
drive.flush_and_unmount()
print('Drive unmounted')

# Mount the drive with force_remount=True
drive.mount('/content/drive1', force_remount=True)
print('Drive mounted')

# Commented out IPython magic to ensure Python compatibility.
import os
from glob import glob
import re
import numpy as np
import cv2
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow

# %matplotlib inline



video_path = '/content/drive1/Shareddrives/AI_Ember_Detection/P2pro_thermal_videos/Clip1/Clip1.mp4'
output_dir = '/content/drive1/Shareddrives/AI_Ember_Detection/P2pro_thermal_videos/Clip1/Clip1Frames'

"""Here we are first deconstructing an .mp4 video into it's individual frames, which are .jpg files.



"""

import shutil

# Delete any existing frames in output_dir
if os.path.exists(output_dir):
    shutil.rmtree(output_dir)
os.makedirs(output_dir, exist_ok=True)

# Take the clip in video_path and deconstruct it into frames
vidcap = cv2.VideoCapture(video_path)
success,image = vidcap.read()
count = 0
while success:
  cv2.imwrite(os.path.join(output_dir, "{}.png".format(count)), image)
  success,image = vidcap.read()
  count += 1

"""Next, we will implement Frame differencing as shown in this link: https://github.com/itberrios/CV_projects/blob/main/motion_detection/detection_with_frame_differencing.ipynb"""



idx = 159

img1_rgb = cv2.cvtColor(cv2.imread(f"{output_dir}/{idx}.png"), cv2.COLOR_BGR2RGB)
img2_rgb = cv2.cvtColor(cv2.imread(f"{output_dir}/{idx+1}.png"), cv2.COLOR_BGR2RGB)

# convert to grayscale
img1 = cv2.cvtColor(img1_rgb, cv2.COLOR_RGB2GRAY)
img2 = cv2.cvtColor(img2_rgb, cv2.COLOR_RGB2GRAY)

# cap = cv2.VideoCapture(video_path)
# frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)
length = 50
img_list = []
for i in range(length):
  img_list.append(cv2.cvtColor(cv2.imread(f"{output_dir}/{(idx - length) + i}.png"), cv2.COLOR_RGB2GRAY))

"""Find pixel-wise maximum across multiple images."""
# Start with the first image
max_image = img_list[0].copy()

# Compare with each subsequent image
for img in img_list[1:]:  # Iterate from the second image onwards
    max_image = np.maximum(max_image, img)

# img_list_np = np.array(img_list)  # Convert list of images to NumPy array
# average_frame = np.mean(img_list_np, axis=0).astype(np.uint8) # Calculate average along a
cv2_imshow(max_image)

# compute grayscale image difference
grayscale_diff = cv2.subtract(img1, max_image)

fig, ax = plt.subplots(1, 3, figsize=(25, 25))
ax[0].imshow(img1_rgb)
ax[0].set_title('Frame 1')
ax[1].imshow(img2_rgb)
ax[1].set_title('Frame 2')
ax[2].imshow(grayscale_diff*50) # scale the frame difference to show the noise
ax[2].set_title('Max Image');

cv2_imshow(img1)

# clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))

# grayscale_diff = clahe.apply(grayscale_diff)

cv2_imshow(grayscale_diff)

colormap_image = cv2.applyColorMap(grayscale_diff, cv2.COLORMAP_JET)
cv2_imshow(colormap_image)

clamped_diff = np.clip(grayscale_diff, 0, 255)
clamped_diff

cv2_imshow(clamped_diff)

# prompt: Use opencv's Gaussian Blur function on clamped_diff

# blurred_diff = cv2.GaussianBlur(clamped_diff, (5, 5), 0) # Apply Gaussian Blur
# cv2_imshow(blurred_diff)

blurred_diff = clamped_diff

# Step 1: Threshold the blurred difference to create a binary image
# Adjust threshold value (30 here) based on your needs
_, thresh = cv2.threshold(blurred_diff, 60, 240, cv2.THRESH_BINARY)

inverted_image = cv2.bitwise_not(thresh)
thresh = inverted_image

# Step 2: Method A - Use SimpleBlobDetector
# Setup SimpleBlobDetector parameters
params = cv2.SimpleBlobDetector_Params()

# Change thresholds - these detect the bright regions
params.minThreshold = 0
params.maxThreshold = 255

# Filter by area
params.filterByArea = True
params.minArea = 275  # Minimum size of blob
params.maxArea = 1500  # Maximum size of blob

# Filter by circularity
params.filterByCircularity = True  # Motion blobs often aren't circular
params.minCircularity = 0.3  # Adjust as needed

# Filter by convexity
params.filterByConvexity = True
params.minConvexity = 0.89  # Adjust as neede

# Filter by inertia - experiment with this
params.filterByInertia = False
# params.minInertiaRatio = 0.10  # Adjust as needed

# Create detector with parameters
detector = cv2.SimpleBlobDetector_create(params)

# Detect blobs
keypoints = detector.detect(thresh)

# Convert the grayscale image to BGR
result_simple = cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR)

# Draw detected blobs as red circles
for kp in keypoints:
    x, y = kp.pt  # Get coordinates
    radius = 20
    thickness = 2  # Set desired thickness
    cv2.circle(result_simple, (int(x), int(y)), radius, (0, 0, 255), thickness)  # Red in BGR

# Display results
cv2_imshow(blurred_diff)
cv2_imshow(thresh)
cv2_imshow(result_simple)
# cv2_imshow(result_contour)
# cv2.waitKey(0)
# cv2.destroyAllWindows()

"""Superimpose the coordinates of the blobs over the origional image"""

# Store coordinates in a list of tuples
coordinates = [(kp.pt[0], kp.pt[1]) for kp in keypoints]

# Print or save the coordinates
print("Blob Coordinates:")
for coord in coordinates:
    print(f"x: {coord[0]}, y: {coord[1]}")

x = coord[0]
y = coord[1]
print(f"(x, y): {x}, {y}")

# Define the radius of the circle
radius = 20  # Replace with your desired radius

# Define the color of the circle (red in BGR)
color = (0, 0, 255)

# Define the thickness of the circle outline (-1 fills the circle)
thickness = 2

# Draw the circle on the image
cv2.circle(colormap_image, (int(x), int(y)), radius, color, thickness)

# Display the image with the circle
cv2_imshow(colormap_image)

colormap_image_rgb = cv2.cvtColor(colormap_image, cv2.COLOR_BGR2RGB)
result_simple_rgb = cv2.cvtColor(result_simple, cv2.COLOR_BGR2RGB)

fig, ax = plt.subplots(1, 3, figsize=(25, 25))
ax[0].imshow(img1_rgb)
ax[0].set_title('Original frame')
ax[1].imshow(result_simple_rgb)
ax[1].set_title('Result after Heuristic-Based Algorithm')
ax[2].imshow(colormap_image_rgb)
ax[2].set_title('Final Overlay with Color Map');

